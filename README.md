# Singing-Voice-Separation

# ğŸ¶ Singing Voice Separation â€“ Replications

This repo contains two Jupyter notebooks replicating classic papers on **singing voice separation**.

## ğŸ“„ Papers

1. **Spleeter: Music Source Separation Tool with Pre-trained Models**  
   Hennequin et al., 2018  
   [arXiv:1812.01278](https://arxiv.org/abs/1812.01278)  
   â†’ [`Utrain.ipynb`](./Utrain.ipynb)

2. **Monoaural Audio Source Separation using Deep Convolutional Neural Networks**  
   Chandna et al., ISMIR 2017  
   [PDF](https://archives.ismir.net/ismir2017/paper/000171.pdf)  
   â†’ [`ConvTrain.ipynb`](./ConvTrain.ipynb)

## ğŸ§  Techniques

- **U-Net (Spleeter-inspired)**  
  Encoderâ€“decoder with skip connections on STFT spectrograms, learning timeâ€“frequency masks.  
  Optimized with MSE on reconstructed vocals/accompaniment.

- **Fully Convolutional Network (ISMIR 2017)**  
  Deep CNN stack without dense layers, operating directly on spectrograms.  
  Learns binary masks for vocal vs. background.

## âš™ï¸ Implementation

- Framework: Python + PyTorch (in notebooks)  
- Input: Mixture audio â†’ STFT log-magnitude spectrograms  
- Output: Separated vocals and accompaniment (via inverse STFT)  
- Dataset: MUSDB18 (or similar)  

---

### ğŸš€ Files
- `Utrain.ipynb` â€“ U-Net training pipeline  
- `ConvTrain.ipynb` â€“ CNN training pipeline  

---

### ğŸ“Œ References
- Hennequin, R. et al., *Spleeter*, arXiv:1812.01278 (2018)  
- Chandna, P. et al., *Deep CNNs for Voice Separation*, ISMIR 2017  
